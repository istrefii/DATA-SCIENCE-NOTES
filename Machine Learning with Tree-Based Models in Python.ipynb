{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import trait_split\n",
    "df= pd.read_csv('https://assets.datacamp.com/production/repositories/1796/datasets/0eb6987cb9633e4d6aa6cfd11e00993d2387caa4/wbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate a DecisionTreeClassifier 'dt' with a maximum depth of 6\n",
    "dt = DecisionTreeClassifier(max_depth=6, random_state=1)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "print(y_pred[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Import accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Compute test set accuracy  \n",
    "acc = accuracy_score(y_pred,y_test )\n",
    "print(\"Test set accuracy: {:.2f}\".format(acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression from sklearn.linear_model\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "\n",
    "# Instatiate logreg\n",
    "logreg = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fit logreg to the training set\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Define a list called clfs containing the two classifiers logreg and dt\n",
    "clfs = [logreg, dt]\n",
    "\n",
    "# Review the decision regions of the two classifiers\n",
    "plot_labeled_decision_regions(X_test, y_test, clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification tree Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=8, random_state=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Instantiate dt_entropy, set 'entropy' as the information criterion\n",
    "dt_entropy = DecisionTreeClassifier(max_depth=8, criterion='entropy', random_state=1)\n",
    "\n",
    "# Fit dt_entropy to the training set\n",
    "dt_entropy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved by using entropy:  0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# Import accuracy_score from sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Use dt_entropy to predict test set labels\n",
    "y_pred= dt_entropy.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy_entropy\n",
    "accuracy_entropy = accuracy_score(y_pred, y_test)\n",
    "\n",
    "# Print accuracy_entropy\n",
    "print('Accuracy achieved by using entropy: ', accuracy_entropy)\n",
    "\n",
    "# Print accuracy_gini\n",
    "#print('Accuracy achieved by using the gini index: ', accuracy_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree for regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url= 'https://assets.datacamp.com/production/repositories/1796/datasets/3781d588cf7b04b1e376c7e9dda489b3e6c7465b/auto.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>origin</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>US</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>Asia</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>Europe</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  displ   hp  weight  accel  origin  size\n",
       "0  18.0  250.0   88    3139   14.5      US  15.0\n",
       "1   9.0  304.0  193    4732   18.5      US  20.0\n",
       "2  36.1   91.0   60    1800   16.4    Asia  10.0\n",
       "3  18.5  250.0   98    3525   19.0      US  15.0\n",
       "4  34.3   97.0   78    2188   15.8  Europe  10.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv(url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mpg', 'displ', 'hp', 'weight', 'accel', 'size', 'origin_Asia',\n",
      "       'origin_Europe', 'origin_US'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create dummy variables: df_region\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "# Print the columns of df_region\n",
    "print(df_region.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>size</th>\n",
       "      <th>origin_Asia</th>\n",
       "      <th>origin_Europe</th>\n",
       "      <th>origin_US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>98</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>18.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3021</td>\n",
       "      <td>16.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>27.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>90</td>\n",
       "      <td>2950</td>\n",
       "      <td>17.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>29.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>68</td>\n",
       "      <td>2135</td>\n",
       "      <td>16.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>17.5</td>\n",
       "      <td>250.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3520</td>\n",
       "      <td>16.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>25.1</td>\n",
       "      <td>140.0</td>\n",
       "      <td>88</td>\n",
       "      <td>2720</td>\n",
       "      <td>15.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  displ   hp  weight  accel  size  origin_Asia  origin_Europe  \\\n",
       "0    18.0  250.0   88    3139   14.5  15.0            0              0   \n",
       "1     9.0  304.0  193    4732   18.5  20.0            0              0   \n",
       "2    36.1   91.0   60    1800   16.4  10.0            1              0   \n",
       "3    18.5  250.0   98    3525   19.0  15.0            0              0   \n",
       "4    34.3   97.0   78    2188   15.8  10.0            0              1   \n",
       "..    ...    ...  ...     ...    ...   ...          ...            ...   \n",
       "387  18.0  250.0   88    3021   16.5  15.0            0              0   \n",
       "388  27.0  151.0   90    2950   17.3  10.0            0              0   \n",
       "389  29.5   98.0   68    2135   16.6  10.0            1              0   \n",
       "390  17.5  250.0  110    3520   16.4  15.0            0              0   \n",
       "391  25.1  140.0   88    2720   15.4  10.0            0              0   \n",
       "\n",
       "     origin_US  \n",
       "0            1  \n",
       "1            1  \n",
       "2            0  \n",
       "3            1  \n",
       "4            0  \n",
       "..         ...  \n",
       "387          1  \n",
       "388          1  \n",
       "389          0  \n",
       "390          1  \n",
       "391          1  \n",
       "\n",
       "[392 rows x 9 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>origin_Asia</th>\n",
       "      <th>origin_Europe</th>\n",
       "      <th>origin_US</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>231.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3907</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>108.0</td>\n",
       "      <td>75</td>\n",
       "      <td>2350</td>\n",
       "      <td>16.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>146.0</td>\n",
       "      <td>97</td>\n",
       "      <td>2815</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.0</td>\n",
       "      <td>78</td>\n",
       "      <td>2188</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>140.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>86.0</td>\n",
       "      <td>65</td>\n",
       "      <td>2019</td>\n",
       "      <td>16.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>91.0</td>\n",
       "      <td>68</td>\n",
       "      <td>1970</td>\n",
       "      <td>17.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>350.0</td>\n",
       "      <td>125</td>\n",
       "      <td>3900</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>350.0</td>\n",
       "      <td>175</td>\n",
       "      <td>4100</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>98.0</td>\n",
       "      <td>60</td>\n",
       "      <td>2164</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     displ   hp  weight  accel  origin_Asia  origin_Europe  origin_US  size\n",
       "21   231.0  110    3907   21.0            0              0          1  15.0\n",
       "157  108.0   75    2350   16.8            1              0          0  10.0\n",
       "358  146.0   97    2815   14.5            1              0          0  15.0\n",
       "4     97.0   78    2188   15.8            0              1          0  10.0\n",
       "338  140.0   86    2790   15.6            0              0          1  10.0\n",
       "..     ...  ...     ...    ...          ...            ...        ...   ...\n",
       "135   86.0   65    2019   16.4            1              0          0  10.0\n",
       "160   91.0   68    1970   17.6            1              0          0  10.0\n",
       "166  350.0  125    3900   17.4            0              0          1  20.0\n",
       "91   350.0  175    4100   13.0            0              0          1  20.0\n",
       "90    98.0   60    2164   22.1            0              0          1  10.0\n",
       "\n",
       "[313 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= df[['displ','hp', 'weight', 'accel', 'origin_Asia', 'origin_Europe', 'origin_US', 'size' ]]\n",
    "y= df.mpg\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=0.2)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=8, min_samples_leaf=0.13, random_state=3)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import DecisionTreeRegressor from sklearn.tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeRegressor(max_depth=8,\n",
    "             min_samples_leaf=0.13,\n",
    "            random_state=3)\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of dt: 3.52\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute y_pred\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Compute mse_dt\n",
    "mse_dt = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute rmse_dt\n",
    "rmse_dt = mse_dt**(1/2)\n",
    "\n",
    "# Print rmse_dt\n",
    "print(\"Test set RMSE of dt: {:.2f}\".format(rmse_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(n_jobs=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr= LinearRegression(n_jobs=1, normalize=False, copy_X=True, fit_intercept=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression test set RMSE: 3.98\n",
      "Regression Tree test set RMSE: 3.52\n"
     ]
    }
   ],
   "source": [
    "# Predict test set labels \n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# Compute mse_lr\n",
    "mse_lr = MSE(y_test, y_pred_lr)\n",
    "\n",
    "# Compute rmse_lr\n",
    "rmse_lr = mse_lr**(1/2)\n",
    "\n",
    "# Print rmse_lr\n",
    "print('Linear Regression test set RMSE: {:.2f}'.format(rmse_lr))\n",
    "\n",
    "# Print rmse_dt\n",
    "print('Regression Tree test set RMSE: {:.2f}'.format(rmse_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization Error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> As the complexity of f increases, the bias term decreases while the variance term increases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnose bias and variance problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      18.0\n",
       "1       9.0\n",
       "2      36.1\n",
       "3      18.5\n",
       "4      34.3\n",
       "       ... \n",
       "387    18.0\n",
       "388    27.0\n",
       "389    29.5\n",
       "390    17.5\n",
       "391    25.1\n",
       "Name: mpg, Length: 392, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set SEED for reproducibility\n",
    "SEED = 1\n",
    "\n",
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=SEED)\n",
    "\n",
    "# Instantiate a DecisionTreeRegressor dt\n",
    "dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=.26, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE: 5.14\n"
     ]
    }
   ],
   "source": [
    "# Compute the array containing the 10-folds CV MSEs\n",
    "MSE_CV_scores = - cross_val_score(dt, X_train, y_train, cv=10, \n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Compute the 10-folds CV RMSE\n",
    "RMSE_CV = (MSE_CV_scores.mean())**(1/2)\n",
    "\n",
    "# Print RMSE_CV\n",
    "print('CV RMSE: {:.2f}'.format(RMSE_CV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 5.15\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Fit dt to the training set\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the training set\n",
    "y_pred_train = dt.predict(X_train)\n",
    "\n",
    "# Evaluate the training set RMSE of dt\n",
    "RMSE_train = (MSE(y_train, y_pred_train))**(1/2)\n",
    "\n",
    "# Print RMSE_train\n",
    "print('Train RMSE: {:.2f}'.format(RMSE_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dt suffers from high bias because RMSE_CV  RMSE_train and both scores are greater than baseline_RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED=1\n",
    "\n",
    "# Instantiate lr\n",
    "lr = LogisticRegression(random_state=SEED)\n",
    "\n",
    "# Instantiate knn\n",
    "knn = KNN(n_neighbors=27)\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=0.13, random_state=SEED)\n",
    "\n",
    "# Define the list classifiers\n",
    "classifiers = [('Logistic Regression', lr), ('K Nearest Neighbours', knn), ('Classification Tree', dt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 579 entries, 0 to 578\n",
      "Data columns (total 12 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   Unnamed: 0                      579 non-null    int64  \n",
      " 1   Age_std                         579 non-null    float64\n",
      " 2   Total_Bilirubin_std             579 non-null    float64\n",
      " 3   Direct_Bilirubin_std            579 non-null    float64\n",
      " 4   Alkaline_Phosphotase_std        579 non-null    float64\n",
      " 5   Alamine_Aminotransferase_std    579 non-null    float64\n",
      " 6   Aspartate_Aminotransferase_std  579 non-null    float64\n",
      " 7   Total_Protiens_std              579 non-null    float64\n",
      " 8   Albumin_std                     579 non-null    float64\n",
      " 9   Albumin_and_Globulin_Ratio_std  579 non-null    float64\n",
      " 10  Is_male_std                     579 non-null    int64  \n",
      " 11  Liver_disease                   579 non-null    int64  \n",
      "dtypes: float64(9), int64(3)\n",
      "memory usage: 54.4 KB\n"
     ]
    }
   ],
   "source": [
    "df1= pd.read_csv('indian_liver_patient_preprocessed.csv')\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Age_std</th>\n",
       "      <th>Total_Bilirubin_std</th>\n",
       "      <th>Direct_Bilirubin_std</th>\n",
       "      <th>Alkaline_Phosphotase_std</th>\n",
       "      <th>Alamine_Aminotransferase_std</th>\n",
       "      <th>Aspartate_Aminotransferase_std</th>\n",
       "      <th>Total_Protiens_std</th>\n",
       "      <th>Albumin_std</th>\n",
       "      <th>Albumin_and_Globulin_Ratio_std</th>\n",
       "      <th>Is_male_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>445</td>\n",
       "      <td>-1.714140</td>\n",
       "      <td>-0.388178</td>\n",
       "      <td>-0.459878</td>\n",
       "      <td>-0.050816</td>\n",
       "      <td>-0.224702</td>\n",
       "      <td>-0.222426</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>1.085338</td>\n",
       "      <td>0.792118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>407</td>\n",
       "      <td>-2.022634</td>\n",
       "      <td>-0.372106</td>\n",
       "      <td>-0.459878</td>\n",
       "      <td>1.757269</td>\n",
       "      <td>0.414556</td>\n",
       "      <td>-0.008337</td>\n",
       "      <td>0.662826</td>\n",
       "      <td>0.707385</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>-0.788658</td>\n",
       "      <td>2.359986</td>\n",
       "      <td>2.382984</td>\n",
       "      <td>0.027260</td>\n",
       "      <td>6.386431</td>\n",
       "      <td>3.244429</td>\n",
       "      <td>-0.998144</td>\n",
       "      <td>-0.678445</td>\n",
       "      <td>-0.147390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>521</td>\n",
       "      <td>0.630415</td>\n",
       "      <td>0.174312</td>\n",
       "      <td>0.499588</td>\n",
       "      <td>-0.252171</td>\n",
       "      <td>-0.366760</td>\n",
       "      <td>-0.294940</td>\n",
       "      <td>0.570550</td>\n",
       "      <td>-1.308368</td>\n",
       "      <td>-1.713237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>498</td>\n",
       "      <td>1.432499</td>\n",
       "      <td>-0.243537</td>\n",
       "      <td>-0.353271</td>\n",
       "      <td>-0.576804</td>\n",
       "      <td>-0.344905</td>\n",
       "      <td>-0.305299</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>1.085338</td>\n",
       "      <td>2.044796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>0.013427</td>\n",
       "      <td>-0.082826</td>\n",
       "      <td>0.073158</td>\n",
       "      <td>-0.116565</td>\n",
       "      <td>-0.131819</td>\n",
       "      <td>-0.156818</td>\n",
       "      <td>-1.274972</td>\n",
       "      <td>-1.056399</td>\n",
       "      <td>-0.460559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>0.013427</td>\n",
       "      <td>0.029672</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>-0.420651</td>\n",
       "      <td>-0.099036</td>\n",
       "      <td>-0.080851</td>\n",
       "      <td>-0.813592</td>\n",
       "      <td>-0.300492</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>1.864391</td>\n",
       "      <td>-0.404249</td>\n",
       "      <td>-0.459878</td>\n",
       "      <td>-0.354903</td>\n",
       "      <td>-0.295731</td>\n",
       "      <td>-0.298393</td>\n",
       "      <td>-1.920905</td>\n",
       "      <td>-1.434352</td>\n",
       "      <td>-0.460559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>236</td>\n",
       "      <td>-1.405646</td>\n",
       "      <td>-0.404249</td>\n",
       "      <td>-0.459878</td>\n",
       "      <td>0.035479</td>\n",
       "      <td>-0.131819</td>\n",
       "      <td>-0.243144</td>\n",
       "      <td>1.308759</td>\n",
       "      <td>0.833369</td>\n",
       "      <td>-0.147390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.075125</td>\n",
       "      <td>1.749283</td>\n",
       "      <td>2.240841</td>\n",
       "      <td>0.339566</td>\n",
       "      <td>-0.235630</td>\n",
       "      <td>-0.115382</td>\n",
       "      <td>-2.013181</td>\n",
       "      <td>-1.434352</td>\n",
       "      <td>-0.460559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   Age_std  Total_Bilirubin_std  Direct_Bilirubin_std  \\\n",
       "441         445 -1.714140            -0.388178             -0.459878   \n",
       "403         407 -2.022634            -0.372106             -0.459878   \n",
       "119         119 -0.788658             2.359986              2.382984   \n",
       "517         521  0.630415             0.174312              0.499588   \n",
       "494         498  1.432499            -0.243537             -0.353271   \n",
       "..          ...       ...                  ...                   ...   \n",
       "129         129  0.013427            -0.082826              0.073158   \n",
       "144         144  0.013427             0.029672              0.002087   \n",
       "72           72  1.864391            -0.404249             -0.459878   \n",
       "235         236 -1.405646            -0.404249             -0.459878   \n",
       "37           37  0.075125             1.749283              2.240841   \n",
       "\n",
       "     Alkaline_Phosphotase_std  Alamine_Aminotransferase_std  \\\n",
       "441                 -0.050816                     -0.224702   \n",
       "403                  1.757269                      0.414556   \n",
       "119                  0.027260                      6.386431   \n",
       "517                 -0.252171                     -0.366760   \n",
       "494                 -0.576804                     -0.344905   \n",
       "..                        ...                           ...   \n",
       "129                 -0.116565                     -0.131819   \n",
       "144                 -0.420651                     -0.099036   \n",
       "72                  -0.354903                     -0.295731   \n",
       "235                  0.035479                     -0.131819   \n",
       "37                   0.339566                     -0.235630   \n",
       "\n",
       "     Aspartate_Aminotransferase_std  Total_Protiens_std  Albumin_std  \\\n",
       "441                       -0.222426            0.755102     1.085338   \n",
       "403                       -0.008337            0.662826     0.707385   \n",
       "119                        3.244429           -0.998144    -0.678445   \n",
       "517                       -0.294940            0.570550    -1.308368   \n",
       "494                       -0.305299            0.016893     1.085338   \n",
       "..                              ...                 ...          ...   \n",
       "129                       -0.156818           -1.274972    -1.056399   \n",
       "144                       -0.080851           -0.813592    -0.300492   \n",
       "72                        -0.298393           -1.920905    -1.434352   \n",
       "235                       -0.243144            1.308759     0.833369   \n",
       "37                        -0.115382           -2.013181    -1.434352   \n",
       "\n",
       "     Albumin_and_Globulin_Ratio_std  Is_male_std  \n",
       "441                        0.792118            1  \n",
       "403                        0.165780            1  \n",
       "119                       -0.147390            1  \n",
       "517                       -1.713237            1  \n",
       "494                        2.044796            1  \n",
       "..                              ...          ...  \n",
       "129                       -0.460559            1  \n",
       "144                        0.165780            0  \n",
       "72                        -0.460559            0  \n",
       "235                       -0.147390            1  \n",
       "37                        -0.460559            0  \n",
       "\n",
       "[463 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1= pd.get_dummies(df1)\n",
    "X= df1.drop('Liver_disease', axis=1)\n",
    "y= df1.Liver_disease\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.733\n",
      "K Nearest Neighbours : 0.707\n",
      "Classification Tree : 0.690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the pre-defined list of classifiers\n",
    "for clf_name, clf in classifiers:    \n",
    " \n",
    "    # Fit clf to the training set\n",
    "    clf.fit(X_train, y_train)    \n",
    "   \n",
    "    # Predict y_pred\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred) \n",
    "   \n",
    "    # Evaluate clf's accuracy on the test set\n",
    "    print('{:s} : {:.3f}'.format(clf_name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Import VotingClassifier from sklearn.ensemble\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Instantiate a VotingClassifier vc\n",
    "vc = VotingClassifier(estimators=classifiers)     \n",
    "\n",
    "# Fit vc to the training set\n",
    "vc.fit(X_train, y_train)   \n",
    "\n",
    "# Evaluate the test set predictions\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('Voting Classifier: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, n_estimators=50, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of bc: 0.69 \n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=.2, stratify=y, random_state=1)\n",
    "# Fit bc to the training set\n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate acc_test\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "print('Test set accuracy of bc: {:.2f} '.format(acc_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of Bag Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(min_samples_leaf=8, random_state=1)\n",
    "\n",
    "# Instantiate bc\n",
    "bc = BaggingClassifier(base_estimator=dt, \n",
    "            n_estimators=50,\n",
    "            oob_score=True,\n",
    "            random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.672, OOB accuracy: 0.706\n"
     ]
    }
   ],
   "source": [
    "# Fit bc to the training set \n",
    "bc.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = bc.predict(X_test)\n",
    "\n",
    "# Evaluate test set accuracy\n",
    "acc_test = accuracy_score(y_pred, y_test)\n",
    "\n",
    "# Evaluate OOB accuracy\n",
    "acc_oob = bc.oob_score_\n",
    "\n",
    "# Print acc_test and acc_oob\n",
    "print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests (RF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike = pd.read_csv('https://assets.datacamp.com/production/repositories/1796/datasets/594538f54a854b322d6e4c8031f3f31bc522d3e5/bikes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>temp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>instant</th>\n",
       "      <th>mnth</th>\n",
       "      <th>yr</th>\n",
       "      <th>Clear to partly cloudy</th>\n",
       "      <th>Light Precipitation</th>\n",
       "      <th>Misty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>149</td>\n",
       "      <td>13004</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>93</td>\n",
       "      <td>13005</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.0896</td>\n",
       "      <td>90</td>\n",
       "      <td>13006</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>33</td>\n",
       "      <td>13007</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>4</td>\n",
       "      <td>13008</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hr  holiday  workingday  temp   hum  windspeed  cnt  instant  mnth  yr  \\\n",
       "0   0        0           0  0.76  0.66     0.0000  149    13004     7   1   \n",
       "1   1        0           0  0.74  0.70     0.1343   93    13005     7   1   \n",
       "2   2        0           0  0.72  0.74     0.0896   90    13006     7   1   \n",
       "3   3        0           0  0.72  0.84     0.1343   33    13007     7   1   \n",
       "4   4        0           0  0.70  0.79     0.1940    4    13008     7   1   \n",
       "\n",
       "   Clear to partly cloudy  Light Precipitation  Misty  \n",
       "0                       1                    0      0  \n",
       "1                       1                    0      0  \n",
       "2                       1                    0      0  \n",
       "3                       1                    0      0  \n",
       "4                       1                    0      0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= bike.drop('cnt', axis=1)\n",
    "y= bike.cnt\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y, test_size=.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=25, random_state=2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate rf\n",
    "rf = RandomForestRegressor(n_estimators=25,\n",
    "            random_state=2)\n",
    "            \n",
    "# Fit rf to the training set    \n",
    "rf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of rf: 54.49\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the test set RMSE\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of rf: {:.2f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc2a3bb54f0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a pd.Series of features importances\n",
    "importances = pd.Series(data=rf.feature_importances_,\n",
    "                        index= X_train.columns)\n",
    "\n",
    "# Sort importances\n",
    "importances_sorted = importances.sort_values()\n",
    "\n",
    "# Draw a horizontal barplot of importances_sorted\n",
    "importances_sorted.plot(kind='barh', color='lightgreen', title='Features Importances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to predict whether a patient suffers from a liver disease using 10 features including Albumin, age and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "\n",
    "# Instantiate ada\n",
    "ada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ada to the training set\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Compute the probabilities of obtaining the positive class\n",
    "y_pred_proba = ada.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.64\n"
     ]
    }
   ],
   "source": [
    "# Import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Evaluate test-set roc_auc_score\n",
    "ada_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print('ROC AUC score: {:.2f}'.format(ada_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting (GB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate gb\n",
    "gb = GradientBoostingRegressor(max_depth=4, \n",
    "            n_estimators=200,\n",
    "            random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit gb to the training set\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of gb: 49.537\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute MSE\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_test = mse_test ** (1/2)\n",
    "\n",
    "# Print RMSE\n",
    "print('Test set RMSE of gb: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Boosting (SGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate sgbr\n",
    "sgbr = GradientBoostingRegressor(max_depth=4, \n",
    "            subsample=0.9,\n",
    "            max_features=0.75,\n",
    "            n_estimators=200,                                \n",
    "            random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit sgbr to the training set\n",
    "sgbr.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = sgbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of sgbr: 47.260\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute test set MSE\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute test set RMSE\n",
    "rmse_test = mse_test ** (1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of sgbr: {:.3f}'.format(rmse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning a CART's Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DecisionTreeClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params_dt\n",
    "params_dt = {\n",
    "\n",
    "    'max_depth':[2,3,4],\n",
    "    'min_samples_leaf':[0.12,0.14,0.16,0.18]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt= DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 4],\n",
       "                         'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROC AUC score: 0.738\n"
     ]
    }
   ],
   "source": [
    "# Import roc_auc_score from sklearn.metrics \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning a RF's Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dictionary 'params_rf'\n",
    "params_rf = {\n",
    "    'n_estimators':[100,350,500],\n",
    "    'max_features':['log2', 'auto', 'sqrt'],\n",
    "    'min_samples_leaf':[2,10,30]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf= RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_rf\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'max_features': ['log2', 'auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [2, 10, 30],\n",
       "                         'n_estimators': [100, 350, 500]},\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of best model: 54.382\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE \n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = MSE(y_test, y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
